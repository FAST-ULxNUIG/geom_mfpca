%!TEX root=../supplement.tex
\section{Basis decomposition} % (fold)
\label{sub:basis_decomposition}


In many practical situations, functional data are noisy and only observed at specific time points. To extract the underlying functional features of the data, smoothing and interpolation techniques are commonly employed. These techniques involve approximating the true underlying function generating the data by a finite-dimensional set of basis functions. Assume that for each feature $p \in \{1, \dots, P\}$, there exists a set of basis of functions $\Psi^{(p)} = \{\psi_k^{(p)}\}_{k \in \{1, \dots, K_p\}}$ such that each feature of each curve $n \in \{1, \dots, N\}$ can be expanded using the basis:
\begin{equation}\label{eq:curve_basis_expansion}
\Xnp(t_p) = \sum_{k = 1}^{K_p} c^{(p)}_{nk}\psi_k^{(p)}(t_p), \quad t_p \in \TT{p},
\end{equation}
where $\{c^{(p)}_{nk}\}_{k \in \{1, \dots, K_p\}}$ is a set of coefficients for feature $p$ of observation $n$. We denote by $\overline{c}_k^{(p)} = \sum_{n = 1}^N \pi_n c^{(p)}_{nk}$ the mean coefficient of feature $p$ corresponding to the $k$th basis function.
The $p$th feature of the mean function can be then expanded in the same basis as:
\begin{equation}
    \hatmup{p}(t_p) = \sum_{k = 1}^{K_p} \overline{c}_k^{(p)}\psi_k^{(p)}(t_p), \quad t_p \in \TT{p}.
\end{equation}
Similarly, the covariance function of the $p$th and $q$th features is given by:
\begin{equation}
    \widehat{C}_{p,q}(s_p, t_q) = \sum_{k = 1}^{K_p} \sum_{l = 1}^{K_q} \left(\sum_{n = 1}^N \pi_n c^{(p)}_{nk}c^{(q)}_{nl} - \overline{c}_k^{(p)}\overline{c}_l^{(q)}\right)\psi_k^{(p)}(s_p)\psi_l^{(q)}(t_q), \quad s_p \in \TT{p},\quad t_q \in \TT{q}.
\end{equation}
These formulas can be written in matrix form as follows. For $\pointt \in \TT{}$, we have that $X(\pointt) = \mathbf{C}\Psi(\pointt)$ where $X(\pointt)$ is a $N \times P$ matrix with entries $\Xnp(t_p),~t_p \in \TT{p},~p \in \{1, \dots,  P\},~n \in \{1, \dots, N\}$,
\begin{equation}
    \mathbf{C} = \begin{pmatrix}
            \mathbf{C}^{(1)} & \cdots & \mathbf{C}^{(P)} \\
        \end{pmatrix}, \quad \text{and}\quad
    \Psi(\pointt) = \text{diag}\{\Psi^{(1)}(t_1), \dots, \Psi^{(P)}(t_P)\},
\end{equation}
where
\begin{equation}
\mathbf{C}^{(p)} = \begin{pmatrix}
    c^{(p)}_{11} & \cdots & c^{(p)}_{1K_p} \\
    \vdots & \ddots & \vdots \\
    c^{(p)}_{N1} & \cdots & c^{(p)}_{NK_p}
\end{pmatrix} \\
\quad \text{and}\quad
\Psi^{(p)}(t_p) = \begin{pmatrix}
    \psi_1^{(p)}(t_p) \\
    \vdots \\
    \psi_{K_p}^{(p)}(t_p)
\end{pmatrix}.
\end{equation}
Using the basis expansion and denoting $\Pi^\top = (\pi_1, \dots, \pi_N)$, the mean and covariance functions are given by
\begin{equation}
    \widehat{\mu}(\pointt) = \Psi(\pointt)^\top \mathbf{C}^\top\Pi \quad\text{and}\quad \widehat{C}(\points, \pointt) = \Psi(\points)^\top \mathbf{C}^\top \left(\text{diag}\{
        \pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right)\mathbf{C} \Psi(\pointt).
\end{equation}
Finally, we denote by $\mathbf{W}$ the matrix of inner products of the functions in the basis $\Psi$. The matrix $\mathbf{W}$ is a block-diagonal matrix such that $\mathbf{W} = \text{blockdiag}\{\mathbf{W}^{(1)}, \dots, \mathbf{W}^{(P)}\}$ where each entry is given by
\begin{equation}
    \mathbf{W}_{k, l}^{(p)} = \inLp{\psi_k^{(p)}}{\psi_l^{(p)}}, \quad k, l \in \{1, \dots, K_p\}, \quad p \in \{1, \dots, P\}.
\end{equation}
We remark that, if the basis $\Psi$ is an orthonormal basis, the matrix $\mathbf{W}$ is equal to the identity matrix of size $\sum_{p = 1}^P K_p$.
Using the expansion of the data into the basis of functions $\Psi$, the inner-product matrix $\mathbf{M}$ is written 
\begin{equation}\label{eq:gram_matrix_basis}
    \mathbf{M} = \text{diag}\{
        \sqrt{\pi_1}, \dots, \sqrt{\pi_N}\}\left(\mathrm{I}_{\!N} - \mathbf{1}_{\!N}\Pi^\top\right) \mathbf{C} \mathbf{W} \mathbf{C}^\top \left(\mathrm{I}_{\!N} - \Pi\mathbf{1}_{\!N}^\top\right)\text{diag}\{
        \sqrt{\pi_1}, \dots, \sqrt{\pi_N}\}
\end{equation}
where $\mathrm{I}_{\!N}$ is the identity matrix of size $N$ and $\mathbf{1}_{\!N}$ is a vector of $1$ of length $N$.


% subsection basis_decomposition (end)


\section{MFPCA with a basis expansion} % (fold)
\label{sub:with_a_basis_expansion}

In this section, we assume that the observations are expanded into a basis of functions, as explained in Section~\ref{sub:basis_decomposition}. Using the expansion of the data into the basis of function $\Psi$ and $\mathbf{W}$, the matrix of inner products of the functions in the basis $\Psi$, we write \eqref{eq:gram_matrix_basis} as
\begin{equation}
    \mathbf{M} = \left(\text{diag}\{
        \sqrt{\pi_1}, \dots, \sqrt{\pi_N}\}\left(\mathrm{I}_{\!N} - \mathbf{1}_{\!N}\Pi^\top\right) \mathbf{C}\mathbf{W}^{1/2}\right)\left(\text{diag}\{
        \sqrt{\pi_1}, \dots, \sqrt{\pi_N}\}\left(\mathrm{I}_{\!N} - \mathbf{1}_{\!N}\Pi^\top\right) \mathbf{C}\mathbf{W}^{1/2}\right)^\top.
\end{equation}
We note
\begin{equation}
    \mathbf{A} = \text{diag}\{\sqrt{\pi_1}, \dots, \sqrt{\pi_N}\}\left(\mathrm{I}_{\!N} - \mathbf{1}_{\!N}\Pi^\top\right) \mathbf{C}\mathbf{W}^{1/2},
\end{equation}
such that $\mathbf{M} = \mathbf{A}\mathbf{A}^\top$.
We also assume that $\phi_1, \phi_2, \dots$ the eigenfunctions of the covariance operator $\Gamma$ have a decomposition into the basis $\Psi$
\begin{equation}
    \phi_k(\cdot) = 
        \begin{pmatrix} 
            \phi_k^{(1)}(\cdot) \\
            \vdots \\
            \phi_k^{(P)}(\cdot)
        \end{pmatrix} = 
        \begin{pmatrix} 
            \psi^{(1) \top}(\cdot) b_{1k} \\
            \vdots \\
            \psi^{(P) \top}(\cdot) b_{Pk}
        \end{pmatrix}, \quad\text{where}\quad
        b_{pk} = \left(b_{p k 1}, \dots, b_{p k K_p} \right)^\top.
\end{equation}
We have, for $p \in \{1, \dots, P\}$,
\begin{align*}
    \left(\Gamma \phi_k\right)^{(p)}(\cdot) &= \sum_{q = 1}^P \int_{\TT{q}} C_{p, q}(\cdot, s_q)\phi_k^{(q)}(s_q) \dd s_q \\
    &= \sum_{q = 1}^P \int_{\TT{q}} \Psi(\cdot)^{(p) \top} \mathbf{C}^{(p) \top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right)\mathbf{C}^{(q)} \Psi^{(q)}(s_q) \Psi^{(q)}(s_q)^\top b_{q k} \dd s_q \\
    &= \Psi(\cdot)^{(p) \top} \mathbf{C}^{(p) \top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right)\sum_{q = 1}^P \mathbf{C}^{(q)} \int_{\TT{q}} \Psi^{(q)}(s_q) \Psi(s_q)^{(q) \top} \dd s_q b_{q k} \\
    &= \Psi(\cdot)^{(p) \top} \mathbf{C}^{(p) \top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right) \sum_{q = 1}^P \mathbf{C}^{(q)} \mathbf{W}^{(q)} b_{q k}. \\
\end{align*}
This equation is true for all $p \in \{1, \dots, P\}$, this can be rewritten with matrices as
\begin{equation}
    \Gamma \phi_k(\cdot) = \Psi(\cdot)^{\top} \mathbf{C}^{\top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right) \mathbf{C} \mathbf{W} b_{k}.
\end{equation}
From the eigenequation, we have that
\begin{equation}
    \Gamma \phi_k(\cdot) = \lambda_k \phi_k(\cdot) \Longleftrightarrow \Psi(\cdot)^{\top} \mathbf{C}^{\top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right) \mathbf{C} \mathbf{W} b_{k} = \lambda_k \Psi(\cdot)^\top b_k.
\end{equation}
Since this equation must be true for all $t_p \in \TT{p}$, this imply the equation
\begin{equation}\label{eq:eigen_decom}
    \mathbf{C}^{\top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right) \mathbf{C} \mathbf{W} b_{k} = \lambda_k b_k.
\end{equation}
As the eigenfunctions are assumed to be normalized, $\normH{\phi_k}^2 = 1$. And so, $b_k^\top \mathbf{W} b_k = 1$. Let $u_k = \mathbf{W}^{1/2}b_k$. Then, from \eqref{eq:eigen_decom}, we obtain
\begin{equation}\label{eq:eigen_cov_op}
    \mathbf{W}^{1/2} \mathbf{C}^{\top} \left(\text{diag}\{\pi_1, \dots, \pi_N\} - \Pi\Pi^\top\right) \mathbf{C} \mathbf{W}^{1/2} u_k = \lambda_k u_k \Longleftrightarrow \mathbf{A}^\top\mathbf{A} u_k = \lambda_k u_k.
\end{equation}
From the eigendecomposition of the matrix $M$, we get
\begin{equation}\label{eq:eigen_inner_prod}
    \mathbf{M}\boldsymbol{u}_k = \ell_k \boldsymbol{u}_k \Longleftrightarrow \mathbf{A}\mathbf{A}^\top \boldsymbol{u}_k = \ell_k \boldsymbol{u}_k.
\end{equation}
The equations \eqref{eq:eigen_cov_op} and \eqref{eq:eigen_inner_prod} are eigenequations in the classical PCA case, with the duality $X^\top X$ and $XX^\top$. Following \cite{pagesMultipleFactorAnalysis2014,hardleAppliedMultivariateStatistical2019}, we find that, for $1 \leq k \leq K$,
\begin{equation}
    \lambda_k = \ell_k, \quad \boldsymbol{u}_k = \frac{1}{\sqrt{\ell_k}}\mathbf{A} u_k \quad\text{and}\quad u_k = \frac{1}{\sqrt{\ell_k}} \mathbf{A}^\top \boldsymbol{u}_k.
\end{equation}
And finally, to get the coefficient of the eigenfunctions, for $k \in \{1, \dots, K\}$,
\begin{equation}
    b_k = \mathbf{W}^{-1/2}u_k = \frac{1}{\sqrt{\ell_k}} \mathbf{C}^\top \left(\mathrm{I}_{\!N} - \Pi\mathbf{1}_{\!N}^\top\right) \text{diag}\{\sqrt{\pi_1}, \dots, \sqrt{\pi_N}\}\boldsymbol{u}_k.
\end{equation}

% subsection with_a_basis_expansion (end)

% section basis_decomposition (end)