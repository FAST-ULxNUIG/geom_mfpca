%!TEX root=../main.tex
\section{Discussion and conclusion} % (fold)
\label{sec:discussion}

MFPCA is a fundamental statistical tool for the analysis of multivariate functional data, which enables us to capture the variability in observations defined by multiple curves. In this paper, we have described the duality between rows and columns of a data matrix within the context of multivariate functional data. We have proposed to use this duality to estimate the eigencomponents of the covariance operator in multivariate functional datasets. By comparing the results of the two methods, we provide the researcher with guidelines for determining the most appropriate method within a range of functional data frameworks. 
%In summary, if the number of sampling points is significantly greater than the number of observations, or if the data are multidimensional (e.g., surfaces), it is preferable to estimate the eigencomponents using the Gram matrix. Conversely, if the data are unidimensional with a large number of observations, the preferred method is the direct decomposition of the covariance operator, regarless of the number of features.
Overall, our simulations showed that the diagonalization of the covariance operator or of the Gram matrix gave similar results in terms of the estimation of the eigenvalues, the eigenfunctions and reconstruction of the curves for one-dimensional multivariate functional data, while the performance of the diagonalization of the Gram matrix outperformed the FCP-TPA for higher-dimensional functional datasets. Regarding the computation time, the use of the covariance operator is faster in most cases for multivariate functional data defined on unidimensional domains. The only situation where the use of the Gram matrix is quicker is when $M \gg N$. For data defined on higher-dimensional domains, diagonalization of the Gram matrix is faster.
In conclusion, we recommend to use the covariance operator for multivariate functional data with all features defined on a one-dimensional domeins (curves) and for a number of observations larger or comparable to the number of sampling points regardless of the number of features. If the data are defined on multi-dimensional domains (images) or the number of sampling points is much higher than the number of observations, we advise using the Gram matrix.

Utilizing the Gram matrix enables the estimation of the number of components retained via the percentage of variance explained by the multivariate functional data, whereas the decomposition of the covariance operator necessitates the specification of the percentage of variance accounted for by each individual univariate feature. Specifying the percentage of variance explained for each feature does not guarantee that we recover the nominal percentage of variance explained for the multivariate data. Although we have not investigated the extent to which this might be important, the duality relation derived in this work provides a direct solution to the problem. Future work could investigate the settings in which univariate variance-explained cutoffs fail to retain the correct percentage of variance explained in multivariate functional data, and hence where the Gram matrix approach may be preferred.

In practice, observations of (multivariate) functional data are often subject to noise. As we recommend the use of the Gram matrix solely for densely sampled functional datasets, individual curve smoothing should suffice to approximate the Gram matrix in such cases. The estimation of the Gram matrix in the context of sparsely sampled functional data is however deemed irrelevant, given our findings that the utilization of the covariance operator for the estimation of the eigencomponents yields comparable results, while typically requiring less computational time.

The open-source implementation can be accessed at \url{https://github.com/StevenGolovkine/FDApy}, while scripts to reproduce the simulations are at \url{https://github.com/FAST-ULxNUIG/geom_mfpca}.


% section discussion (end)