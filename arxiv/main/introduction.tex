%!TeX root=../main.tex
\section{Introduction} % (fold)
\label{sec:introduction}

% ----------------------------------------------------------------------------
% General introduction to FDA and FPCA
% ----------------------------------------------------------------------------
\textcolor{red}{Functional data analysis (FDA) is a statistical methodology for analyzing data that can be represented as functions. These functions could represent measurements taken over time or space, such as temperature readings over a period of time or spatial patterns of disease occurrence. The goal of FDA is to extract meaningful information from these functions and to model their behavior. In this article, we will provide a general introduction to FDA, including its history, key concepts, and applications.}
FPCA is usally used as a preprocessing step to feed regression and classification models.

\textcolor{blue}{Neuroscience: MFPCA has been used to analyze brain imaging data to identify patterns of brain activity across multiple brain regions. This can help to better understand the neural mechanisms underlying various cognitive processes and disorders.
Climate Science: MFPCA has been used to analyze spatiotemporal climate data to identify patterns of temperature and precipitation variability across multiple regions. This can help to better understand the drivers of climate change and variability.
Finance: MFPCA has been used to analyze multivariate financial time series data to identify common patterns of market behavior across multiple stocks. This can help to better understand market trends and to develop more accurate financial forecasting models.
Genetics: MFPCA has been used to analyze gene expression data to identify patterns of gene expression across multiple tissues or conditions. This can help to better understand the underlying biological mechanisms involved in various diseases and disorders.
Environmental Monitoring: MFPCA has been used to analyze multivariate spatiotemporal environmental monitoring data, such as water quality or air pollution data, to identify patterns of environmental variability across multiple regions. This can help to identify areas where environmental regulations or remediation efforts may be necessary.}

\textcolor{blue}{To start, we should first define what multivariate functional principal components analysis (MFPCA) is. MFPCA is a statistical technique that is used to analyze multivariate functional data, which are data that consist of multiple functions that are observed simultaneously. MFPCA is based on the idea of functional principal components analysis (FPCA), which is a technique for analyzing single functional data sets.
In MFPCA, we seek to decompose the covariance structure of the multivariate functional data into a set of orthogonal basis functions, or principal components, which capture the main sources of variation in the data. These basis functions are determined by eigenanalysis of the covariance matrix of the multivariate functional data.
To conduct an MFPCA analysis, we first need to collect multivariate functional data. This data can come from a variety of sources, such as medical imaging, environmental monitoring, or financial data analysis. Once we have collected the data, we can then apply the MFPCA technique to the data to extract the principal components.
One of the key benefits of MFPCA is that it allows us to identify and visualize the main sources of variation in the multivariate functional data. This can be useful in many different applications, such as identifying patterns of gene expression in genomics, analyzing changes in brain activity in neuroscience, or predicting financial market trends in economics.
When writing an article on MFPCA, it is important to provide a clear explanation of the technique and its applications, as well as a detailed description of the data used in the analysis and the results obtained. It may also be useful to discuss any limitations or assumptions of the MFPCA technique, as well as any extensions or modifications that have been proposed in the literature.
In addition to discussing the technical details of the MFPCA technique, it is important to write the article in a clear and concise manner, using appropriate statistical and mathematical notation where necessary. The article should be structured in a logical and organized manner, with clear headings and subheadings to guide the reader through the analysis.}

% ----------------------------------------------------------------------------
% General approaches for FPCA and MFPCA
% ----------------------------------------------------------------------------
\textcolor{red}{General approaches for FPCA and MFPCA}

\begin{itemize}

\item Most of the existing methods for FPCA are build upon \cite{ramsayFunctionalDataAnalysis2005} paper. 

\item Stack the multivariate observation into one and perform usual FPCA \cite{ramsayFunctionalDataAnalysis2005}

\item Expand each curves into a basis of functions \cite{jacquesModelbasedClusteringMultivariate2014a}

\item Normed FPCA \cite{jacquesModelbasedClusteringMultivariate2014a,chiouMultivariateFunctionalPrincipal2014}, different type of normalization for both of them.

\item PCA for each time point \cite{berrenderoPrincipalComponentsMultivariate2011}

\item Develop general methodology for MFPCA \cite{happMultivariateFunctionalPrincipal2015}, allows multidimensional data and basis expansion.
\end{itemize}

\textcolor{blue}{From ChatGPT
Direct Extension of FPCA: The simplest approach to MFPCA is to perform functional principal components analysis (FPCA) on each of the functional variables separately and then combine the principal components across the variables to obtain a multivariate decomposition. This approach is sometimes referred to as "direct extension" of FPCA. While this approach is straightforward, it may not fully capture the dependence structure between the functional variables.
Kronecker Product Approach: The Kronecker product approach involves taking the Kronecker product of the covariance functions of the individual functional variables to obtain a joint covariance function for the multivariate functional data. This joint covariance function can then be used to perform FPCA to obtain the multivariate principal components.
Reduced Rank Regression Approach: The reduced rank regression approach involves modeling the multivariate functional data as a linear combination of a small number of basis functions. The coefficients of the linear combination are then modeled as multivariate Gaussian random variables, and the covariance structure of the coefficients is used to perform the MFPCA.
Tensor Decomposition Approach: The tensor decomposition approach involves decomposing the multivariate functional data into a higher-order tensor, and then performing a tensor-based decomposition to obtain the multivariate principal components. This approach can be useful when dealing with very high-dimensional functional data.
Bayesian Approaches: Bayesian approaches to MFPCA involve specifying a prior distribution on the principal components and the covariance matrix of the multivariate functional data, and then using Bayesian inference to estimate the posterior distribution of the parameters. Bayesian approaches can be useful when dealing with complex dependence structures and small sample sizes.
}

% ----------------------------------------------------------------------------
% Key motivations of the paper -> Duality between rows and colums of a matrix
% ----------------------------------------------------------------------------
\textcolor{red}{Key motivations of the paper -- Duality between rows and colums of a matrix}
\textcolor{blue}{the duality between rows and columns of a data matrix is a fundamental concept in classical statistics that can be used to understand the relationship between different types of statistical analyses.
In classical statistics, a data matrix typically represents a set of observations of multiple variables, where each row corresponds to an individual observation and each column corresponds to a variable. The duality between rows and columns refers to the fact that many statistical analyses can be conducted either on the rows or the columns of the data matrix, and the resulting analyses will be related to each other in a specific way.
For example, consider a data matrix where the rows represent individual subjects and the columns represent different measurements taken on each subject, such as blood pressure, weight, and age. Conducting a principal component analysis (PCA) on the columns of this data matrix will result in a set of principal components that capture the variability in the different measurements across all subjects. These principal components can be interpreted as patterns of co-variation across the different measurements.
Alternatively, conducting a PCA on the rows of the same data matrix will result in a set of principal components that capture the variability in the measurements across different subjects. These principal components can be interpreted as patterns of co-variation across the different subjects.
The duality between rows and columns means that the principal components obtained from these two different analyses will be related in a specific way. Specifically, the principal components obtained from the column PCA can be used to predict the principal components obtained from the row PCA, and vice versa. This relationship can be expressed mathematically as a matrix transpose operation, where the columns of the original data matrix become the rows of the transposed data matrix, and vice versa.
In the context of multivariate functional principal components analysis (MFPCA), the duality between rows and columns can be used to understand the relationship between the principal components obtained from the analysis of multiple functional variables observed on the same set of subjects or units. This duality is particularly useful when dealing with high-dimensional functional data where it may not be feasible to analyze all the functional variables at once.}
The key motivation of the paper is that in a large number of applications, the number of components of the functional datasets is very large, and estimating the eigencomponents of the covariance operator require the diagonalisation of each univariate component which can be computationaly extensive. Using the duality between rows and colums of the data matrix reduce the number of matrix disgonalisation to only one. Another arguments is that for data defined on multidimensional domains, the estimation of the covariance operator remains unclear (how to compute the covariance of 2-dimensional data?). The use of the inner-product matrix allows the eigencomponents of multidimensional data to be computed.

Duality of usual matrix \cite{escofierTraitementSimultaneVariables1979,saportaSimultaneousAnalysisQualitative1990,pagesAnalyseFactorielleDonnees2004,hardleAppliedMultivariateStatistical2019}


% ----------------------------------------------------------------------------
% Duality for funcitonal data
% ----------------------------------------------------------------------------
\textcolor{red}{Duality in the functional data case}
For functional data, \cite{ramsayWhenDataAre1982a} explains the duality of the space of functions and the space of time points. Used in \cite{benkoCommonFunctionalPrincipal2009} for univariate and unidimensional functional data. \cite{chenQuantifyingInfiniteDimensionalData2017}


% ----------------------------------------------------------------------------
% Rest of the paper
% ----------------------------------------------------------------------------
\textcolor{red}{Remainder of the paper.}
The remainder of the paper is organized as follows. In Section~\ref{sec:model}, we define multivariate functional data with the coordinates possibly having different definition domains. In Section~\ref{sec:geometric_point_of_view_mfpca}, we develop the duality between the observations' space and the functional components space. The relationship between the eigencomponents of the covariance operator of the functional datasets and the eigencomponents of the inner-product matrix between the observations is derived in Section~\ref{sec:functional_principal_components_analysis}. Extensive simulations are given in Section~\ref{sec:simulations}. We also provide guidelines on the method to use in which case. The paper concludes with a discussion and an outlook in Section~\ref{sec:discussion}.

% section introduction (end)