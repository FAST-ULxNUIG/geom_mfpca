%!TeX root=../main.tex
\section{Introduction} % (fold)
\label{sec:introduction}

% ----------------------------------------------------------------------------
% General introduction to FDA and FPCA
% ----------------------------------------------------------------------------
Functional data analysis (FDA) is a statistical methodology for analyzing data that can be represented as functions. These functions could represent measurements taken over time or space, such as temperature readings over a period of time or spatial patterns of disease occurrence. The goal of FDA is to extract meaningful information from these functions and to model their behavior. See, e.g., \cite{ramsayFunctionalDataAnalysis2005,horvathInferenceFunctionalData2012,wangFunctionalDataAnalysis2016,kokoszkaSpecialIssueFunctional2017} for some recent references on functional data analysis.

Functional principal component analysis (FPCA) is an extension of principal component analysis (PCA), which is a commonly used tool for dimension reduction in multivariate data, to functional data. This tool has been introduced by \cite{karhunenUeberLineareMethoden1947} and \cite{loeveFonctionsAleatoiresStationnaires1945} and developed by \cite{dauxoisAsymptoticTheoryPrincipal1982}. Since then, FPCA has become a prevalent tool in FDA due to its ability to convert infinite-dimensional functional data into a finite-dimensional vector of random scores. These scores are a countable sequence of uncorrelated random variables that can be truncated to a finite vector in practical applications. By applying multivariate data analysis tools to these random scores, FPCA can achieve the goal of dimension reduction while assuming mild assumptions about the underlying stochastic process. FPCA is usually used as a preprocessing step to feed regression and classification models. Recently, FPCA has been extended to the analysis of multivariate functional data, which are data that consist of multiple functions that are observed simultaneously. This extension is referred to as multivariate functional data analysis (MFPCA). As for FPCA, a key benefit of MFPCA is that it allows to identify and visualize the main sources of variation in the multivariate functional data. This can be useful in many different applications, such as identifying patterns of movements in sport biomechanics \citep{warmenhovenBivariateFunctionalPrincipal2019}, analyzing changes in brain activity in neuroscience \citep{songSparseMultivariateFunctional2022}, or comparing  countries' competitiveness in economics \citep{krzyskoMultidimensionalEconomicIndicators2022}.

% ----------------------------------------------------------------------------
% General approaches for FPCA and MFPCA
% ----------------------------------------------------------------------------
In MFPCA, we seek to decompose the covariance structure of the multivariate functional data into a set of orthogonal basis functions, named the principal components, which capture the main sources of variation in the data. There are multiple approaches to estimate the principal components of a multivariate functional dataset. \cite{ramsayFunctionalDataAnalysis2005} stack the multivariate curves into one big curve and then perform an usual FPCA by doing an eigendecomposition of the covariance structure. This methodology can only be run for data that are defined on the same unidimensional domain and that exhibit similar variations. \cite{jacquesModelbasedClusteringMultivariate2014a} propose to expand each univariate component into a basis of functions. It results in a set of coefficients for each univariate curve. The eigendecomposition is then run on the matrix of the stacked coefficients. To consider the normalization issue of \cite{ramsayFunctionalDataAnalysis2005}, \cite{jacquesModelbasedClusteringMultivariate2014a} and \cite{chiouMultivariateFunctionalPrincipal2014} propose to normalize the data by the standard deviation of the curves at each sampling points. \cite{happMultivariateFunctionalPrincipal2015} extend the estimation to functional data defined on different dimensional domains. The estimation is based on FPCA for each univariate component and use a weighted combinaison of them to obtain the multivariate eigencomponents. Finally, \cite{berrenderoPrincipalComponentsMultivariate2011} develop a very different method to estimate the eigencomponents as they perform a principal components analysis for each sampling time points.

% ----------------------------------------------------------------------------
% Key motivations of the paper -> Duality between rows and colums of a matrix
% ----------------------------------------------------------------------------
The key motivation of the paper is to investigate the duality between rows and columns of a data matrix to estimate the eigencomponents of a multivariate functional dataset. The duality between rows and columns of a data matrix is a fundamental concept in classical statistics \citep{escofierTraitementSimultaneVariables1979,saportaSimultaneousAnalysisQualitative1990}. A data matrix typically represents a set of observations of multiple features, each row corresponds to an individual observation and each column correspond to an individual feature. The duality between rows and columns refers to the fact that many statistical methodologies can be conducted either on the rows of the columns of the data matrix, and the results will be related to each other. For example, the principal components obtained from a PCA run on the rows of the data matrix can be used to compute the principal components obtained from a PCA run on the columns of the matrix. The choice of method to use, based on criteria such as computational time or data storage, is thus left to the statistician. This concept has been widely studied for multivariate statistics (see, e.g., \cite{pagesMultipleFactorAnalysis2014,hardleAppliedMultivariateStatistical2019}). In the context of functional data, this principle has not been explored much. \cite{ramsayFunctionalDataAnalysis2005} briefly commented on it in a concluding remark of Chapter~8. \cite{kneipInferenceDensityFamilies2001,benkoCommonFunctionalPrincipal2009} utilized it to compute principal components for dense univariate functional data. \cite{chenQuantifyingInfiniteDimensionalData2017} also mention it to gain computational advantage when the data are very densely sampled. To the best of our knowledge, however, there is no available literature on its application to multivariate functional data that are observed on different dimensional domains. Our aim is therefore to investigate this duality for multivariate functional data observed on different dimensional domains and provide guidelines to statisticians on which method to use in different cases.

% ----------------------------------------------------------------------------
% Rest of the paper
% ----------------------------------------------------------------------------
The remainder of the paper is organized as follows. In Section~\ref{sec:model}, we define multivariate functional data with the coordinates possibly having different definition domains. In Section~\ref{sec:geometric_point_of_view_mfpca}, we develop the duality between the observations' space and the functional components space. The relationship between the eigencomponents of the covariance operator of the functional datasets and the eigencomponents of the inner-product matrix between the observations is derived in Section~\ref{sec:functional_principal_components_analysis}. Extensive simulations are given in Section~\ref{sec:simulations}. We also provide guidelines on which method to use with respect to data characteristics. The paper concludes with a discussion and an outlook in Section~\ref{sec:discussion}.

% section introduction (end)